# 问题描述

在某个CPU#110上出现大量的软锁报错:
```sh
...
[4158131.484488] watchdog: BUG: soft lockup - CPU#110 stuck for 22s! [kworker/u257:2:236027]
[4158171.485473] watchdog: BUG: soft lockup - CPU#110 stuck for 22s! [kworker/u257:2:236027]
[4158199.486164] watchdog: BUG: soft lockup - CPU#110 stuck for 23s! [kworker/u257:2:236027]
...
```

日志中的其中一个堆栈信息如下:
```sh
[4158171.485473] watchdog: BUG: soft lockup - CPU#110 stuck for 22s! [kworker/u257:2:236027]
...
[4158171.485532] Workqueue: xprtiod rpc_async_schedule [sunrpc]
[4158171.485540] RIP: 0010:kfree+0xb1/0x160
...
[4158171.485553] Call Trace:
[4158171.485559]  __kfree_skb+0xe/0x20
[4158171.485562]  sk_stream_alloc_skb+0x106/0x1e0
[4158171.485565]  tcp_sendmsg_locked+0x515/0xd30
[4158171.485573]  tcp_sendmsg+0x27/0x40
[4158171.485576]  sock_sendmsg+0x36/0x40
[4158171.485586]  xs_send_kvec+0xb7/0xc0 [sunrpc]
[4158171.485597]  xs_sendpages+0x5d/0x200 [sunrpc]
[4158171.485615]  xs_tcp_send_request+0xa7/0x240 [sunrpc]
[4158171.485646]  xprt_transmit+0x68/0x360 [sunrpc]
[4158171.485673]  call_transmit+0x1cb/0x2a0 [sunrpc]
[4158171.485683]  __rpc_execute+0x7f/0x3e0 [sunrpc]
[4158171.485687]  process_one_work+0x195/0x3d0
[4158171.485689]  worker_thread+0x30/0x390
[4158171.485693]  kthread+0x113/0x130
[4158171.485697]  ret_from_fork+0x22/0x40
```

整理了日志中堆栈的代码流程，可以看出是在`__rpc_execute()`中不断循环。
```c
__rpc_execute
  call_transmit
    xprt_transmit
      xs_tcp_send_request
        xs_sendpages
          xs_send_kvec
            sock_sendmsg
              tcp_sendmsg
                tcp_sendmsg_locked
                  sk_stream_alloc_skb
                    __kfree_skb
                      kfree
                release_sock
                  tcp_release_cb
        xs_nospace
          spin_unlock_bh
            raw_spin_unlock_bh
              _raw_spin_unlock_bh
                __raw_spin_unlock_bh
                  __local_bh_enable_ip
                    do_softirq
          xs_tcp_write_space
    xprt_prepare_transmit
      spin_unlock_bh
        raw_spin_unlock_bh
          _raw_spin_unlock_bh
            __raw_spin_unlock_bh
              __local_bh_enable_ip
                do_softirq
  __x86_indirect_thunk_r15+0x3/0x11
  __x86_indirect_thunk_rax+0x3/0x20
  __x86_indirect_thunk_rcx+0x3/0x20
  __x86_indirect_thunk_r15+0x0/0x11
```

# vmcore分析

## 准备

```sh
crash> mod | grep nfs # 可以看出，使用的是nfsv3
ffffffffc0397000  nfs_acl                   16384  (not loaded)  [CONFIG_KALLSYMS]
ffffffffc03ef100  nfsv3                     49152  fs/nfs/nfsv3.ko.debug 
ffffffffc066dc80  nfs                      311296  fs/nfs/nfs.ko.debug
# 加载调试的ko
crash> mod -s sunrpc net/sunrpc/sunrpc.ko.debug
crash> mod -s nfs fs/nfs/nfs.ko.debug
crash> mod -s nfsv3 fs/nfs/nfsv3.ko.debug
# crash> mod -s nfsv4 fs/nfs/nfsv4.ko.debug
```

注意这个vmcore是执行`echo 1 > /proc/sys/kernel/softlockup_panic`后导出的。

## 找到触发rpc任务的进程

查看崩溃时的堆栈:
```sh
crash> bt
PID: 236027  TASK: ffff99b651d44680  CPU: 110  COMMAND: "kworker/u257:2"
 #0 [ffff9ab03eb83d50] machine_kexec at ffffffff8725a70e
 #1 [ffff9ab03eb83da8] __crash_kexec at ffffffff8735b001
 #2 [ffff9ab03eb83e68] panic at ffffffff872b310e
 #3 [ffff9ab03eb83ef0] watchdog_timer_fn at ffffffff8738f21b
 #4 [ffff9ab03eb83f20] __hrtimer_run_queues at ffffffff8733ae98
 #5 [ffff9ab03eb83f80] hrtimer_interrupt at ffffffff8733b615
 #6 [ffff9ab03eb83fd8] smp_apic_timer_interrupt at ffffffff87c025ba
 #7 [ffff9ab03eb83ff0] apic_timer_interrupt at ffffffff87c01b1f
--- <IRQ stack> ---
 #8 [ffffaa3eedaebd98] apic_timer_interrupt at ffffffff87c01b1f
    [exception RIP: __x86_indirect_thunk_r15+3]
    RIP: ffffffff87e031c3  RSP: ffffaa3eedaebe40  RFLAGS: 00000286
    RAX: 0000000000000005  RBX: ffff9a3319bd4a18  RCX: 0000000000000006
    RDX: 0000000000000000  RSI: 0000000000000000  RDI: ffff9a3319bd4a18
    RBP: ffff9ab0343e0400   R8: ffff9a7c2c187a40   R9: ffff9ab035efba60
    R10: ffffe1aa188d9600  R11: ffff9a89fa993440  R12: 0000000000000000
    R13: 0000000000000001  R14: ffffffffc1063860  R15: ffffffffc10597a0
    ORIG_RAX: ffffffffffffff13  CS: 0010  SS: 0018
 #9 [ffffaa3eedaebe40] __rpc_execute at ffffffffc1063f6f [sunrpc]
#10 [ffffaa3eedaebe98] process_one_work at ffffffff872d0915
#11 [ffffaa3eedaebed8] worker_thread at ffffffff872d0b80
#12 [ffffaa3eedaebf10] kthread at ffffffff872d72f3
#13 [ffffaa3eedaebf50] ret_from_fork at ffffffff87c00202
```

```sh
crash> dis -rl ffffffffc1063f6f
...
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 783
0xffffffffc1063f67 <__rpc_execute+119>: mov    %rbx,%rdi
0xffffffffc1063f6a <__rpc_execute+122>: callq  0xffffffff87e031c0 <__x86_indirect_thunk_r15>
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/./arch/x86/include/asm/bitops.h: 318
0xffffffffc1063f6f <__rpc_execute+127>: mov    0x30(%rbx),%rax
```

可以看出`__x86_indirect_thunk_r15+3`是执行到`__rpc_execute()`的`do_action(task)`。

反汇编`__rpc_execute()`，重点看`%rdi`寄存器相关的内容:
```sh
crash> dis -l __rpc_execute
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 753
...
0xffffffffc1063efe <__rpc_execute+14>:  push   %rbx
0xffffffffc1063eff <__rpc_execute+15>:  mov    %rdi,%rbx # 将寄存器 rdi 中的值复制到寄存器 rbx 
0xffffffffc1063f02 <__rpc_execute+18>:  sub    $0x20,%rsp
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 755
0xffffffffc1063f06 <__rpc_execute+22>:  movzwl 0xdc(%rdi),%r13d
...
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/./arch/x86/include/asm/bitops.h: 318
0xffffffffc1063f2b <__rpc_execute+59>:  mov    0x30(%rbx),%rax
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 761
...
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/./arch/x86/include/asm/bitops.h: 318
0xffffffffc1063f37 <__rpc_execute+71>:  mov    0x30(%rbx),%rax
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 756
...
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 776
0xffffffffc1063f4d <__rpc_execute+93>:  mov    0x18(%rbx),%r15
0xffffffffc1063f51 <__rpc_execute+97>:  test   %r15,%r15
0xffffffffc1063f54 <__rpc_execute+100>: je     0xffffffffc106400b <__rpc_execute+283>
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 778
0xffffffffc1063f5a <__rpc_execute+106>: movq   $0x0,0x18(%rbx) # 不会改变 %rbx 的值
0xffffffffc1063f62 <__rpc_execute+114>: nopl   0x0(%rax,%rax,1)
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 783
0xffffffffc1063f67 <__rpc_execute+119>: mov    %rbx,%rdi
0xffffffffc1063f6a <__rpc_execute+122>: callq  0xffffffff87e031c0 <__x86_indirect_thunk_r15>
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/./arch/x86/include/asm/bitops.h: 318
0xffffffffc1063f6f <__rpc_execute+127>: mov    0x30(%rbx),%rax
/usr/src/debug/kernel-4.19.90/linux-4.19.90-23.15.v2101.ky10.x86_64/net/sunrpc/sched.c: 788
```

x86_64下整数参数使用的寄存器依次为: `RDI，RSI，RDX，RCX，R8，R9`，所以`%rdi`（也赋值到了`%rbx`）的值就是`__rpc_execute(struct rpc_task *task)`第一个参数的值。

我们再尝试找到触发rpc任务的进程:
```sh
crash> struct rpc_task ffff9a3319bd4a18 # RDI: ffff9a3319bd4a18
struct rpc_task {
  ...
  tk_owner = 227403,
  ...
}
```

确认一下这个进程的状态信息:
```sh
crash> ps | grep 227403
   PID    PPID   CPU       TASK         ST  %MEM      VSZ     RSS  COMM
  227403  25069  108  ffff9ab00f915e00  IN   0.3 14366732 3565828  dmap_br
```

查看这个进程的栈:
```sh
crash> bt 227403
PID: 227403  TASK: ffff9ab00f915e00  CPU: 108  COMMAND: "dmap_br"
 #0 [ffffaa3edc39fc40] __schedule at ffffffff87a9a4e6
 #1 [ffffaa3edc39fce0] schedule at ffffffff87a9ab88
 #2 [ffffaa3edc39fce8] futex_wait_queue_me at ffffffff8734cb51
 #3 [ffffaa3edc39fd20] futex_wait at ffffffff8734d9db
 #4 [ffffaa3edc39fe40] do_futex at ffffffff87350187
 #5 [ffffaa3edc39fec0] __x64_sys_futex at ffffffff8735074b
 #6 [ffffaa3edc39ff38] do_syscall_64 at ffffffff8720430b
 #7 [ffffaa3edc39ff50] entry_SYSCALL_64_after_hwframe at ffffffff87c00088
    RIP: 00007f9182bc310c  RSP: 00007ffdf17cb660  RFLAGS: 00000246
    RAX: ffffffffffffffda  RBX: 00007f918076eb48  RCX: 00007f9182bc310c
    RDX: 0000000000000000  RSI: 0000000000000080  RDI: 00007f918076eb70
    RBP: 0000000000000000   R8: 0000000000000000   R9: 0000000000000000
    R10: 0000000000000000  R11: 0000000000000246  R12: 00007f918076eb20
    R13: 0000000000000000  R14: 0000000000000000  R15: 00007f918076eb70
    ORIG_RAX: 00000000000000ca  CS: 0033  SS: 002b
```

## 找到rpc请求的类型

解析rpc任务结构体:
```sh
crash> struct rpc_task ffff9a3319bd4a18 # RDI: ffff9a3319bd4a18
struct rpc_task {
  tk_msg = {
    rpc_proc = 0xffffffffc03eb8a0 <nfs3_procedures+288>, 
    rpc_argp = 0xffff9a3319bd4bd8, 
    rpc_resp = 0xffff9a3319bd4c40, 
    rpc_cred = 0xffff9ab0283d2e00
  }, 
```

`nfs3_procedures[]`是`struct rpc_procinfo`类型的数组，`struct rpc_procinfo`结构体的大小如下:
```sh
crash> struct rpc_procinfo
struct rpc_procinfo {
  ...
}
SIZE: 48
```

从`<nfs3_procedures+288>`中的偏移量`288`计算出`288/48=6`，查看`fs/nfs/nfs3xdr.c`文件中的以下代码:
```c
const struct rpc_procinfo nfs3_procedures[] = {                    
        PROC(GETATTR,           getattr,        getattr,        1),
        PROC(SETATTR,           setattr,        setattr,        0),
        PROC(LOOKUP,            lookup,         lookup,         2),
        PROC(ACCESS,            access,         access,         1),
        PROC(READLINK,          readlink,       readlink,       3),
        PROC(READ,              read,           read,           3),
        PROC(WRITE,             write,          write,          4),
```

可知rpc请求类型是`NFS3PROC_WRITE`。

# 代码分析

由vmcore解析可知rpc请求类型是`NFS3PROC_WRITE`，只有`nfs3_proc_write_setup()`函数中引用这个宏定义。

# 补丁

- `ed0172af5d6f SUNRPC: Fix a race to wake a sync task`

<!--
```
我们观察到，NFS 客户端在 __rpc_execute 中的同步任务在等待 RPC_TASK_QUEUED 时没有响应来自 rpc_make_runnable() 的唤醒。 我怀疑这个问题通常不会被注意到，因为在一个忙碌的客户端上，任务最终会通过另一个任务完成或 xprt 事件重新被唤醒。然而，如果状态管理器正在清空插槽表，一个没有被唤醒的同步任务可能会导致客户端挂起。

我们已经能够证明，rpc_make_runnable() 中的唤醒操作会成功调用 wake_up_bit()（即没有竞争条件影响 tk_runstate），但 wake_up_bit() 的调用没有唤醒等待者。我怀疑唤醒者缺少对位的 wait_queue_head 的加载，所以 waitqueue_active() 返回 false。在 wake_up_bit()、prepare_to_wait() 和 waitqueue_active() 之上有一些非常有用的注释，帮助说明了这个问题。

通过在 wake_up_bit() 之前插入 smp_mb__after_atomic()，来解决这个问题，这样可以与 prepare_to_wait() 调用的 set_current_state() 成对使用。
```
-->

- `6258cf25d5e3 SUNRPC: avoid soft lockup when transmitting UDP to reachable server.`

<!--
```
SUNRPC：避免在向可达服务器传输 UDP 时发生软锁死

在下面提到的提交之前，call_transmit_status() 会处理与无法访问的服务器相关的错误（如 -EPERM），通过跳转到 call_status() 来处理，这会添加一个 3 秒的延迟，并将失败视为超时。

自从该提交之后，call_transmit_status() 直接跳转到 handle_bind()。对于 UDP，这会直接进入 handle_connect() 和 handle_transmit()，因此我们立即重新传输，很可能会遇到相同的错误。

这导致了 __rpc_execute() 中的无限循环，并触发了软锁死警告。

对于那些表示无法访问的服务器的错误，call_transmit_status() 应该像以前一样回退到 call_status()。这样做不会导致之前补丁所避免的“雷鸣般的洪流”，因为 call_status() 会插入一个延迟。
```
-->

